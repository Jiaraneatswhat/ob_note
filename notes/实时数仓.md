# 1. 维度表设计
- 离线数仓中，普通维度表通过主维表和相关维表做关联查询生成，对应的业务数据是通过每日一次<font color='skyblue'>全量同步</font>到 `HDFS` 中，只需每日做一次全量数据的关联查询
- 实时数仓采集的是所有表的变化数据，一旦主维表或相关维表中的某张数据表数据发生了变化，就需要和其他表的历史数据做关联
- 获取历史数据的方法：
	- 在某张与维度表相关的业务数据表发生变化时，执行一次 `maxwell-bootstrap` 命令，将相关业务维度表的数据导入 `Kafka`
		- 缺点：
			- `Kafka` 会存储冗余数据
			-  需要组件来执行 `maxwell-bootstrap` 命令
			- 数据进入流中的时间不同，可能会出现 `join` 不到的情况，影响时效性
	- 维度表发生变化时去 `HBase` 中读取关联后的维表，筛选出受影响的数据，与变更后的数据进行关联再写入 `HBase`
		- 缺点：一条数据发生变化后，受到影响的数据可能会特别多，影响效率
	- 将分表导入 `HBase`，在 `HBase` 中进行关联
		- 缺点：`HBase` 的 `join` 性能很差，关联操作不在 `Stream` 的 `DAG` 图中，需要单独调度
	- 综上，对业务表做 `join` 形成维度表的方式不适用于实时数仓
- 在实时数仓中，不再对业务数据库中的维度表进行合并，过滤掉一些不需要的字段后，将维度数据写入 `HBase` 的维度表中
- 实时数仓强调实时性，不保存历史事实数据，但需要考虑历史维度数据，字典表数据量小，选择将其维度字段退化到事实表中
# 2. ODS 
- 需要对维度表相关的数据做一次全量同步
# 3. DIM
- `DIM` 层的数据存储在 `HBase` 表中
## 3.1 基类设计
- `Flink Job` 的处理流程：
	- 初始化流处理环境，配置检查点，从 `Kafka` 读取目标主题数据
	- 执行处理逻辑
	- `execute`
- 将第一步和第三步交给基类完成，定义实现处理逻辑的抽象方法交给子类重写
- 在 `Constant` 类中定义配置信息
- 在 `FlinkSourceUtil` 中定义和 `Kafka` 交互的 `Sink` 和 `Source`
