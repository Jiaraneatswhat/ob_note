# 1.其他框架
## 1.1 DataX
### 1.1.1 原理
- `DataX` 是一个离线异构数据源同步工具
- 主要由三部分组成
	- Reader：数据采集模块，负责采集数据源的数据，将数据发送给 `Framework`
	- Framework：用于连接 `Reader` 和 `Writer`，作为两者的数据传输通道，并处理缓冲，流控，并发，数据转换等问题
	- Writer：数据写入模块，负责不断从 `Framework` 取数据

![[datax1.svg]]

- 运行流程
	- Job：单个数据同步的作业，负责监控并等待多个 `TaskGroup` 模块任务完成，完成后成功退出
	- Task：`DataX` 作业的最小单元，`Job` 启动后根据不同的切分策略将 `Job` 分成多个 `Task`，每个 `Task` 负责一部分数据的同步工作
	- TaskGroup：切分完 `Task` 后，会通过 `Scheduler` 模块将 `Task` 组合成 `TaskGroup`，默认单个 `TaskGroup` 的并发数为 5
	- `TaskGroup` 启动 `Task` 后，通过 `Reader -> Channel -> Writer` 执行同步工作

![[datax2.svg]]

### 1.1.2 做过哪些优化
#### 1.1.2.1 全局
- 提升每个 `Channel` 的速度
	- `DataX` 内部限制
		- 每秒同步的 `record` 的个数
		- 每秒同步的字节数
- 可以将单个 `Channel` 的速度上限增加到 `5MB/s`
```Python
{
"speed":{
	"channel": 2,  # 此处为数据导入的并发度，建议根据服务器硬件进行调优
	"record": -1, # 此处解除对读取行数的限制
	"byte": 5242880, # 此处解除对字节的限制
	"batchSize": 204 # 每次读取batch的大小
	}
}
```
#### 1.1.2.2 局部
- 提升 `Job` 内 `Channel` 的并发数
	- 配置全局 `Byte` 限速以及单` Channel Byte` 限速
		- `Channel 数 = 全局 Byte 限速 / 单 Channel Byte 限速`
	- 配置全局 `Record` 限速以及单 ` Channel Byte` 限速
		- `Channel 数 = 全局 Record 限速 / 单 Channel Byte 限速`
	- 直接配置 `Channel` 个数
#### 1.1.2.3 内存
- 执行 `datax.py` 时直接加参数
	- `python datax/bin/datax.py --jvm="-Xms8G -Xmx8G" /path/to/your/job.json`
### 1.1.3 遇到过什么问题
- Null 值问题
	- MySQL 中的 `null` 值就是 `null`，而 `Hive` 中的 `null` 值用`\N`来存储
	- MySQL -> Hive
		- 建表时手动指定 `null` 值
		- `null defined as ''`
	- Hive -> MySQL
		- 在 DataX 的 hdfsreader 中指定属性
		- `"parameter":{"nullFormat: ""}`
### 1.1.4 与 Sqoop 的比较
- Sqoop 的原理：
	- 仅 `Mapper` 任务的 `MR`
	- 自定义了 `InputFormat` 和 `OutputFormat`
- `DataX` 是一个多进程的线程
- `Sqoop` 支持分布式，`DataX` 可以通过调度系统实现
- `DataX` 有流控功能
- `DataX` 有统计信息和数据校验
### 1.1.5 DataX 为什么不使用增量同步
- DataX 的增量同步是新版本才有的功能，以前搭好的采集系统没有更改
## 1.2 DolphinScheduler
### 1.2.1 DS 挂了怎么办
- 查看日志报错原因
- 一般是资源不够导致，增加资源后重启
### 1.2.2 调度的任务挂了怎么办
- 配置告警及时处理
- 查看日志解决问题
- 重新跑任务
### 1.2.3 什么时候开始调度
- 需要调度的属于全量同步
- 业务数据：每天的 00: 00开始 ---->  `DataX` 全量同步
- 日志数据：每天的 00：30 开始 ----> `Load` 命令将数据加载到 `ODS` 层
	- 在 Flume 中的 HDFS Sink 中设置的滚动文件的周期是 30min
	- 需要等待 30min 防止没有滚动结束
# 2.每天的指标有多少
- 100 个指标，节假日、活动时有大概 150-200 个
- 从用户来说
	- 统计用户的变动情况，回流，流失等
	- 统计用户留存率
	- 统计 1/7/30 日用户的新增和活跃情况
	- 用户的行为漏斗分析
- 从商品来说
	- 统计最近 30 日的复购率
	- 统计 1/7/30 日各品牌下单情况
	-  统计 1/7/30 日各品类下单情况
- 从交易相关来说
	- 统计下单到支付的平均时间间隔
	- 各省份的交易统计
- 从用户的行为日志中
	- 统计各渠道的流量
	- 路径分析
# 3.建模准备
- ER 模型
	- 三范式
		- 第一范式：属性不可分割，保证了数据的可用性
		- 第二范式：非主键字段完全依赖主键，不能存在部分函数依赖，减少了数据冗余
		- 第三范式：非主键字段不能传递依赖于主键，不能存在传递函数依赖，保证了数据的一致性
- 维度模型
- 星型模型：事实表只有一级维度

![[star_schema.svg]]

- 雪花模型：事实表存在多级维度

![[snowflake_schema.svg]]

- 星座模型: 多张事实表存在相同的维度表
- 离线使用星型模型来减少 `join`

- 事实表
	- 概念
		- 由用户行为产生的业务过程数据
	- 导入方式
		- `maxwell` 增量
		- 特殊：加购表为存量型指标，使用全量和增量
	- 种类
		- 事务型事实表
			- 选择业务过程 -> 声明粒度 -> 确定维度 -> 确定事实
			- 缺点：
				- 存量型指标
				- 多事实关联: 需要多张表 `join`
		- 周期型快照事实表
			- 购物车存量
		- 累积型快照事实表
			- 订单下单到完成时间
- 维度表
	- 概念
		- 描述事实发生时的环境信息
	- 导入方式 
		- 全量
		- 特殊：增量 用户信息
	- 维度整合
		- 星型模型需要维度退化
		- ER 模型拆开的表需要整合
		- 商品信息表：`SKU SPU Trademark Category1, 2, 3`
		- 省份信息表：大区表，省份表
		- 活动信息表：活动信息表 活动规则表
	- 拉链表：方便获取历史切片数据
		- 数据量大的缓慢变化维
- 全量同步和增量同步的选择
	- 数据量
		- 小：全量
		- 大：是否会发生修改操作
			- 是：变化的多少
				- 多：全量
				- 少：增量 + 拉链
			- 否：增量
# 4.数仓建模
## 4.1 业务调研
- 所有的业务数据(最好有建表语句)
- 与 Java 部门沟通
- 与组长或项目经理沟通指标
## 4.2 明确数据域
- 用户域：注册，登录
- 流量域：启动，页面，曝光，动作，错误
- 交易域：加购，下单，支付
- 工具域：优惠券相关
- 互动域：评价，收藏
## 4.3 构建业务矩阵
- 找事实表和维度表的关系
## 4.4 维度建模(ODS -> DWD/DIM)
## 4.5 指标体系建设(ADS -> DWS)
- 原子指标：业务过程 + 聚合逻辑 + 度量
- 派生指标：原子指标 + 统计周期 + 统计粒度(维度组合) + 业务限定
- 衍生指标：派生指标再加工   eg：留存率
- 业务相同的一类指标可以放在同一张 `DWS` 表中
# 5.架构

![[framework.svg]]

- 日志数据保存在磁盘文件中，`Flume` 通过 `TailDirSource` 实现断点续传将数据发送给 `Kafka`
- `Kafka` 直接从 `KafkaChannel` 中接收数据，可以省略一个 `Sink`，传输效率更高
- `Kafka` 的作用主要是用于解决读写速度不一致的问题，起到一个缓冲作用
- 为了解决 `Flume` 访问数过多，占用线程池的情况，再通过第二层 `Flume` 将日志数据存储到 `HDFS`
- 第二层 `Flume` 通过 `FileChannel` 将数据持久化到磁盘，通过一个拦截器来解决零点漂移的问题
## 5.1 框架选型
- Apache
- 云服务器：阿里云，华为云(考虑公司和阿里腾讯合作关系)
- 框架版本
	- Hadoop：3.1.3
	- Zookeeper：3.7.1
	- Flume：1.10.0
	- Kafka：3.0.0
	- Hive：3.1.3
	- HBase：2.4.0
	- Spark：3.3.0
	- Flink：1.13.0
- 服务器选型：物理机
## 5.2 集群规模
### 5.2.1 数据量
- 用户行为数据
	- 用户日活 85W，每人一天平均 100 条，共计 8500W 条
	- 每条日志 0.9K，共 `8500W * 0.9 = 73G`
	- ODS 采用 `gzip` 压缩，`73G` 压缩至 `22G` 左右
	- DWD 采用 `snappy + orc` 存储，`25G` 左右
	- DWS 层不足 `10G`，按 `10G` 算 
	- ADS 层忽略不计
	- 保存 3 副本：`57 * 3 = 171G`
	- 1 年内不扩容服务器：`171G * 365 天 = 约 61T`
	- 预留 20%-30%的缓存 `61 / 0.7 = 约 87T`
- Kafka 中的数据
	- 每天约 `73G 数据 * 副本数 2 = 146G`
	- 保存 3 天 * 146G = 438G
	- 预留 30% 的缓存 438 / 0.7 = 623G
- 业务数据
	- 每天活跃用户数 85W，下单 10W，每人产生业务数据 10 条，每条 0.9 k 左右，`10W * 10 * 0.9 = 1G 左右`
	- 数仓五层存储：1G * 3
	- 保存 3 副本：3G * 3
	- 1 年内不扩容服务器：9G * 360 = 约 3.2T
	- 预留 20-30%的缓存：5T
- 总数据量：96T 左右
### 5.2.2 CPU
### 5.2.3 内存
### 5.2.4 部署
- Master 节点
	- 管理节点保证集群调度正常进行
	- 主要部署 `NN`, `RM`, `HMaster` 等
	- `HA` 模式下为 2
- Core 节点
	- 计算及存储
	- 主要部署 `DN`, `NM`, `RegionServer`
	- `HA` 模式下≥3
- Common 节点
	- 为 `HA` 集群 `Master` 提供数据共享同步和高可用容错
	- `ZK` 等
	- `HA` 模式下≥3
- 客户端放在一到两台服务器上，方便外部访问(`Spark`, `Flink`, `Hive`)
- 有依赖关系的尽量放在同一台服务器(如 `DN` 和 `NM`)
### 5.2.5 人员配置
### 5.2.6 从 0 到 1 需要做什么
- 需要问的问题
	- 数据量
	- 日活
	- 数据源
	- 首批指标
	- 未来规划：离线和实时是否都要做
- 项目周期

# 6.每层做了什么事
## 6.1 ODS 层
- Hive 的建表语句
```sql
CREATE [TEMPORARY] [EXTERNAL] TABLE [IF NOT EXISTS] [db_name.]table_name    -- (Note: TEMPORARY available in Hive 0.14.0 and later)
  [(col_name data_type [column_constraint_specification] [COMMENT col_comment], ... [constraint_specification])]
  [COMMENT table_comment]
  [PARTITIONED BY (col_name data_type [COMMENT col_comment], ...)]
  [CLUSTERED BY (col_name, col_name, ...) [SORTED BY (col_name [ASC|DESC], ...)] INTO num_buckets BUCKETS]
  [SKEWED BY (col_name, col_name, ...)                  -- (Note: Available in Hive 0.10.0 and later)]
   ON ((col_value, col_value, ...), (col_value, col_value, ...), ...)
   [STORED AS DIRECTORIES]
   [
       [ROW FORMAT row_format] 
       [STORED AS file_format]
       | STORED BY 'storage.handler.class.name' [WITH SERDEPROPERTIES (...)]  -- (Note: Available in Hive 0.6.0 and later)
   ]
   [LOCATION hdfs_path]
   [TBLPROPERTIES (property_name=property_value, ...)]   -- (Note: Available in Hive 0.6.0 and later)
   [AS select_statement];   -- (Note: Available in Hive 0.5.0 and later; not supported for external tables)

   CREATE [TEMPORARY] [EXTERNAL] TABLE [IF NOT EXISTS] [db_name.]table_name
   LIKE existing_table_or_view_name
   [LOCATION hdfs_path];

   data_type
   : primitive_type
   | array_type
   | map_type
   | struct_type
   | union_type  -- (Note: Available in Hive 0.7.0 and later)

   primitive_type
   : TINYINT
   | SMALLINT
   | INT
   | BIGINT
   | BOOLEAN
   | FLOAT
   | DOUBLE
   | DOUBLE PRECISION -- (Note: Available in Hive 2.2.0 and later)
   | STRING
   | BINARY      -- (Note: Available in Hive 0.8.0 and later)
   | TIMESTAMP   -- (Note: Available in Hive 0.8.0 and later)
   | DECIMAL     -- (Note: Available in Hive 0.11.0 and later)
   | DECIMAL(precision, scale)  -- (Note: Available in Hive 0.13.0 and later)
   | DATE        -- (Note: Available in Hive 0.12.0 and later)
   | VARCHAR     -- (Note: Available in Hive 0.12.0 and later)
   | CHAR        -- (Note: Available in Hive 0.13.0 and later)

   array_type
   : ARRAY < data_type >

   map_type
   : MAP < primitive_type, data_type >

   struct_type
   : STRUCT < col_name : data_type [COMMENT col_comment], ...>

   union_type
   : UNIONTYPE < data_type, data_type, ... >  -- (Note: Available in Hive 0.7.0 and later)

   row_format
   : DELIMITED [FIELDS TERMINATED BY char [ESCAPED BY char]] [COLLECTION ITEMS TERMINATED BY char]
   [MAP KEYS TERMINATED BY char] [LINES TERMINATED BY char]
   [NULL DEFINED AS char]   -- (Note: Available in Hive 0.13 and later)
   | SERDE serde_name [WITH SERDEPROPERTIES (property_name=property_value, property_name=property_value, ...)]

   file_format:
   : SEQUENCEFILE
   | TEXTFILE    -- (Default, depending on hive.default.fileformat configuration)
   | RCFILE      -- (Note: Available in Hive 0.6.0 and later)
   | ORC         -- (Note: Available in Hive 0.11.0 and later)
   | PARQUET     -- (Note: Available in Hive 0.13.0 and later)
   | AVRO        -- (Note: Available in Hive 0.14.0 and later)
   | JSONFILE    -- (Note: Available in Hive 4.0.0 and later)
   | INPUTFORMAT input_format_classname OUTPUTFORMAT output_format_classname

   column_constraint_specification:
   : [ PRIMARY KEY|UNIQUE|NOT NULL|DEFAULT [default_value]|CHECK  [check_expression] ENABLE|DISABLE NOVALIDATE RELY/NORELY ]

   default_value:
   : [ LITERAL|CURRENT_USER()|CURRENT_DATE()|CURRENT_TIMESTAMP()|NULL ] 

   constraint_specification:
   : [, PRIMARY KEY (col_name, ...) DISABLE NOVALIDATE RELY/NORELY ]
   [, PRIMARY KEY (col_name, ...) DISABLE NOVALIDATE RELY/NORELY ]
   [, CONSTRAINT constraint_name FOREIGN KEY (col_name, ...) REFERENCES table_name(col_name, ...) DISABLE NOVALIDATE 
    [, CONSTRAINT constraint_name UNIQUE (col_name, ...) DISABLE NOVALIDATE RELY/NORELY ]
    [, CONSTRAINT constraint_name CHECK [check_expression] ENABLE|DISABLE NOVALIDATE RELY/NORELY ]
```
- 建表方式选择
	- 建多少个表：一种数据一张表
	- 表名
		- 库名区分：`ods.tblname_full/inc`
		- 前缀区分：`ods + tblname + full/inc`
	- 表字段类型以及数据文件存储类型
		- 文本文件
			- 固定分隔符分割
				- 列名和列类型：
					- 采集的日志数据
						- 列名可以根据数据的含义自定义
						- 列类型根据数据自定义
					- MySQL 采集的数据
						- 列名使用 `MySQL` 的列名
						- 列类型也和 `MySQL` 保持一致
				- 表的存储类型：`row format delimited fields terminated by 'sep' stored as textfile` 
			- json 数据
				- 列名和列类型：json 的一级属性名
				- 列存储类型：`row format serde 'org.apache.hadoop.hive.serder2.JsonSerDe' stored as textfile`
		- parquet 或 orc 保存的
			- 列名和列类型：与文件中保持一致
			- 列存储类型：`stored as parquet / orc`
	- 分区：公司中一般按天分区
	- 表数据存储位置：与其他父目录保持一致
	- 表数据是否压缩：是
	- 表压缩格式：`ods` 存放原始数据，数据量比较大，选用压缩比比较高的压缩方式 `gzip`
	- 表数据加载方式
```sql
load data inpath '${hdfs_path}' [overwrite] into table ods_table_name partition(dt='currdate')
```
- Hive 中的复杂数据类型
- array
	- 指定类型：`array<elem_type>`
	- 创建对象：`array(elem1, elem2, ...)`
	- 获取值：`array[index]`
- map
	- 指定类型：`map<k_type, v_type>`
	- 创建对象: `map(k1, v1, k2, v2, ...)`
	- 获取值
		- `map['k']`
		- `map_keys(map)`
		- `map_values(map)`
- struct
	- 指定类型：`struct<col_name: data_type, ...>`
	- 创建对象：
		- 默认属性创建：`struct(attr1, attr2, ...)`，只传属性值
		- 自定义属性创建：`name_struct(attr1_name, attr1_val, ...)`
		- 获取值：`struct.attr`
- `map` 适用于 `key` 的名称和个数不固定的情况
- `struct` 适用于 `key` 的名称和个数以及值的类型固定的情况

- 做的事
	- 保持数据原貌不做修改
	- 压缩采用 `gzip`
	- 创建分区表
## 6.2 DIM 层和 DWD 层
- DIM 层
	- 建表个数
		- 事实表相关的每个维度都需要建一张维度表
		- 维度表属性很少时可以进行维度退化
	- 表名：`dim.tblname_full/zip`
	- 字段名和字段类型
		- 维度表字段 = 主键 + 维度属性
		- 主键 = 主维表的主键
		- 粒度= 主维表的粒度
		- 主维表是与业务直接相关的表
	- 加载数据方式
		- 全量快照维度表的主维表和相关维表都采用全量同步：
		- ` insert overwrite table dim表 partiiton(dt='当日') select ... from ods主维表当日分区 left join ods相关维度当日分区`
- DWD 层
	- 建表个数 = 业务过程个数
	- 表名：`dwd.数据域_tblname_事务型事实表\[inc] / 周期快照\[full] / 累积快照\[acc]`
	- 字段和类型
		- 字段 = 维度外键 + 度量值 + \[冗余的维度]
- DIM 层和 DWD 层查询次数多，都按 `orc` 或 `parquet` 进行列存，都使用 `snappy` 压缩
- 做的事
	- 用 SQL 清洗数据
		- 删除过期数据，过滤重复数据
		- 1 万条数据清洗掉 1 条
		- 脱敏
		- 压缩
		- 列存
- DWS 层 -> 指标建设
- ADS 层 -> 指标

![[e_comm_index.png]]
- <font color='red'>留转 G 复活</font>
# 7.数据量
- ODS 层
	- 1G -> 100W 条
	- 用户行为数据：73G
		- 曝光：44G
		- 页面：15G
		- 动作：7G
		- 故障 + 启动：7G
	- 业务数据：900M
		- 登录：18W，注册：900 左右
		- 加购，增量 18W，全量 90W，下单 9W，支付 7W，取消下单 500，退款 500
		- 领取优惠券 4W，使用优惠券下单 3W，使用优惠券支付 2.5W
		- 点赞评论收藏各 1000
		- 用户(活跃 85W，新增 900，总用户 900W)
		- 商品 SPU(1.6W)，商品 SKU(18W)
- DWD 层 + DIM 层：和 ODS 层几乎一致
- DWS 层：轻度聚合后，30G
- ADS 层：十多 M，可以忽略不计