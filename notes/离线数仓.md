# 1. 使用到的小框架
## 1.1 DataX
### 1.1.1 原理
### 1.1.2 做过哪些优化
#### 1.1.2.1 全局
- 提升每个 `Channel` 的速度
	- `DataX` 内部限制
		- 每秒同步的 `record` 的个数
		- 每秒同步的字节数
- 可以将单个 `Channel` 的速度上限增加到 `5MB/s`
```Python
{
"speed":{
	"channel": 2,  # 此处为数据导入的并发度，建议根据服务器硬件进行调优
	"record": -1, # 此处解除对读取行数的限制
	"byte": 5242880, # 此处解除对字节的限制
	"batchSize": 204 # 每次读取batch的大小
	}
}
```
#### 1.1.2.2 局部
- 提升 `Job` 内 `Channel` 的并发数
	- 配置全局 `Byte` 限速以及单` Channel Byte` 限速
		- `Channel 数 = 全局 Byte 限速 / 单 Channel Byte 限速`
	- 配置全局 `Record` 限速以及单 ` Channel Byte` 限速
		- `Channel 数 = 全局 Record 限速 / 单 Channel Byte 限速`
	- 直接配置 `Channel` 个数
#### 1.1.2.3 内存
- 执行 `datax.py` 时直接加参数
	- `python datax/bin/datax.py --jvm="-Xms8G -Xmx8G" /path/to/your/job.json`
### 1.1.3 遇到过什么问题
- Null 值问题
	- MySQL 中的 `null` 值就是 `null`，而 `Hive` 中的 `null` 值用'\\N'来存储
	- MySQL -> Hive
		- 建表时手动指定 `null` 值
		- `null defined as ''`
	- Hive -> MySQL
		- 在 DataX 的 hdfsreader 中指定属性
		- `"parameter":{"nullFormat: ""}`
### 1.1.4 与 Sqoop 的比较
- Sqoop 的原理：
	- 仅 `Mapper` 任务的 `MR`
	- 自定义了 `InputFormat` 和 `OutputFormat`
- `DataX` 是一个多进程的线程
- `Sqoop` 支持分布式，`DataX` 可以通过调度系统实现
- `DataX` 有流控功能
- `DataX` 有统计信息和数据校验
### 1.1.5 DataX 为什么不使用增量同步
- DataX 的增量同步是新版本才有的功能，以前搭好的采集系统没有更改

## 1.2 DolphinScheduler
### 1.2.1 DS 挂了怎么办
- 查看日志报错原因
- 一般是资源不够导致，增加资源后重启
### 1.2.2 调度的任务挂了怎么办
- 配置告警及时处理
- 查看日志解决问题
- 重新跑任务
### 1.2.3 什么时候开始调度
- 需要调度的属于全量同步
- 业务数据：每天的 00: 00开始 ---->  `DataX` 全量同步
- 日志数据：每天的 00：30 开始 ----> Loadming'l
	- 